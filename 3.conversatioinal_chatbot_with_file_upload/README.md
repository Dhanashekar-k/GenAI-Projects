# ğŸ¤– Conversational RAG Chatbot with PDF Upload & History (Groq + HuggingFace)

This project enables a **conversational Retrieval-Augmented Generation (RAG)** interface over one or more PDFs using:
- ğŸ§  Groq's Gemma2-9B-Instruct as the LLM
- ğŸ’¬ Streamlit for user interaction
- ğŸ“š FAISS for vector store
- ğŸ§¾ Chat history management per session

---

## ğŸ› ï¸ Environment Setup

### 1. Create Conda Environment

```bash
conda create -p ./genai python=3.10 -y
conda activate ./genai
```

### 2. Set Up `.env` File

Create a `.env` file in the root directory with the following:

```env
HF_TOKEN=your_huggingface_token
```

You will be prompted to enter your **Groq API key** at runtime via the Streamlit UI.

---

## ğŸ“¦ Install Requirements

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Run the App

Make sure your PDFs are ready for upload during the session.

```bash
streamlit run app.py
```

---

## ğŸ§  Features

- Upload one or multiple PDF documents
- Process documents using `PyPDFLoader` and chunk with `RecursiveCharacterTextSplitter`
- Create vector embeddings with HuggingFace (`all-MiniLM-L6-v2`)
- Conversational interface with contextual memory
- Uses `create_history_aware_retriever` and `RunnableWithMessageHistory` from LangChain

---

## ğŸ”’ Note
This application **does not store uploaded PDFs** permanently. Uploaded files are temporarily processed for the session.